{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, datediff\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Project').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://Al-PC:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Project</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x78bbe08>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"C:\\\\Users\\\\Al\\\\Desktop\\\\stepik-ds-course\\\\Week3\\\\Project\\\\clickstream.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"C:\\\\Users\\\\Al\\\\Desktop\\\\stepik-ds-course\\\\Week3\\\\Project\\\\result\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+-----+--------+------+---------------+-----------------+------------+-------+---------+---------------------+\n",
      "|      date|               time|event|platform| ad_id|client_union_id|compaign_union_id|ad_cost_type|ad_cost|has_video|target_audience_count|\n",
      "+----------+-------------------+-----+--------+------+---------------+-----------------+------------+-------+---------+---------------------+\n",
      "|2019-04-01|2019-04-01 04:00:48| view| android| 45061|          34734|            45061|         CPM|  200.6|        0|              1955269|\n",
      "|2019-04-01|2019-04-01 04:00:48| view|     web|121288|         121288|           121288|         CPM|  187.4|        0|               232011|\n",
      "|2019-04-01|2019-04-01 04:01:03| view| android|102737|         102535|           102564|         CPC|   60.7|        0|                 4410|\n",
      "+----------+-------------------+-----+--------+------+---------------+-----------------+------------+-------+---------+---------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|count(date)|\n",
      "+-----------+\n",
      "|          6|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.agg(F.countDistinct(\"date\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('date', 'date'),\n",
       " ('time', 'timestamp'),\n",
       " ('event', 'string'),\n",
       " ('platform', 'string'),\n",
       " ('ad_id', 'int'),\n",
       " ('client_union_id', 'int'),\n",
       " ('compaign_union_id', 'int'),\n",
       " ('ad_cost_type', 'string'),\n",
       " ('ad_cost', 'double'),\n",
       " ('has_video', 'int'),\n",
       " ('target_audience_count', 'decimal(10,0)')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "date               | день, в который происходят события\n",
    "time\t           | точное время события\n",
    "event\t           | тип события, может быть или показ или клик по рекламе\n",
    "platform\t       | платформа, на которой произошло рекламное событие\n",
    "ad_id\t           | id рекламного объявления\n",
    "client_union_id\tid |рекламного клиента\n",
    "campaign_union_id  | id рекламной кампании\n",
    "ad_cost_type\t   | тип объявления с оплатой за клики (CPC) или за показы (CPM)\n",
    "ad_cost\t           | стоимость объявления в рублях, для CPC объявлений - это цена за клик, для CPM - цена за 1000 показов\n",
    "has_video\t       | есть ли у рекламного объявления видео\n",
    "target_audience_count | \tразмер аудитории, на которую таргетируется объявление\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = df.randomSplit([0.75, 0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250358"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[1].count() #проверяем что разделилось на части"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits[0].write.parquet(output_path + \"train\\\\\")\n",
    "splits[1].write.parquet(output_path + \"test\\\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Надо:*\n",
    "ad_id\tinteger\t      id рекламного объявления\n",
    "target_audience_count decimal размер аудитории, на которую таргетируется объявление\n",
    "has_video  integer\t    1 если есть видео, иначе 0\n",
    "- is_cpm\tinteger\t    1 если тип объявления CPM, иначе 0\n",
    "- is_cpc\tinteger\t    1 если тип объявления CPC, иначе 0\n",
    "ad_cost\tdouble\t    стоимость объявления в рублях\n",
    "- day_count  integer\tЧисло дней, которое показывалась реклама\n",
    "+ CTR\t  double\t     Отношение числа кликов к числу просмотров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "количество дней показа по объявлению "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_days_count_df = df.filter(df['event'] == 'view') \\\n",
    "                    .groupBy('ad_id') \\\n",
    "                    .agg(F.countDistinct(\"date\"))\\\n",
    "                    .withColumnRenamed('count(date)', 'days_count')\n",
    "#ad_days_count_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CTR (отношение числа кликов к числу просмотров)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-15-126eb3745c13>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-15-126eb3745c13>\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    from clickstream \\\u001b[0m\n\u001b[1;37m                       \n^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "#SparkSQL with SQL exprs:\n",
    "df.createOrReplaceTempView('clickstream') # регистрируем DF как таблицу\n",
    "ctr_df = spark.sql(\"select ad_id, views, clicks, clicks / views as ctr \\\n",
    "                                from (select ad_id,\\\n",
    "                                             count(CASE WHEN event = 'view' THEN 1 END)  as views,\\\n",
    "                                             count(CASE WHEN event = 'click' THEN 1 END) as clicks \\\n",
    "                                      from clickstream \\ \n",
    "                                      group by ad_id \\\n",
    "                                      having views != 0)\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark sql without sql expr:\n",
    "count_cond_lambda = lambda cond: F.sum(F.when(cond, 1).otherwise(0))\n",
    "\n",
    "ctr_df = df.groupBy('ad_id') \\\n",
    "           .agg(count_cond_lambda(F.col('event') == 'view').alias('views'), \\\n",
    "                count_cond_lambda(F.col('event') == 'click').alias('clicks')) \\\n",
    "           .select('ad_id', F.expr(\"clicks / views\").alias('CTR')) \n",
    "ctr_df.show()          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "is_cpm и is_cpc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ndf = df.withColumn('is_cpm', int(col('ad_cost_type') == 'CPM'))\\\n",
    "#        .withColumn('is_cpc', int(col('ad_cost_type') == 'CPC') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ctr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ndf = df.select(['ad_id', \\\n",
    "                 'target_audience_count',  \\\n",
    "                 'has_video', \\\n",
    "                 (col('ad_cost_type') == 'CPM').cast('integer').alias('is_cpm'), \\\n",
    "                 (col('ad_cost_type') == 'CPC').cast('integer').alias('is_cpc'), \\\n",
    "                 'ad_cost']) \\\n",
    "        .join(ad_days_count_df, 'ad_id', 'left') \\\n",
    "        .join(ctr_df, 'ad_id', 'left') \n",
    "ndf.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = ndf.randomSplit([0.75, 0.25])\n",
    "splits[0].write.parquet(output_path + \"train\\\\\")\n",
    "splits[1].write.parquet(output_path + \"test\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits[1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+--------------------+\n",
      "| ad_id|views|                 ctr|\n",
      "+------+-----+--------------------+\n",
      "| 47217|   22|0.045454545454545456|\n",
      "| 40515|  140| 0.02857142857142857|\n",
      "| 33412|   35|                 0.0|\n",
      "| 33602|  480|             0.01875|\n",
      "| 20596|  641|  0.0062402496099844|\n",
      "|119169|  636|0.007861635220125786|\n",
      "|116158| 5589|                 0.0|\n",
      "| 46938|   47| 0.02127659574468085|\n",
      "|114166|   26|                 0.0|\n",
      "| 43921|   22|                 0.0|\n",
      "| 98184|   37| 0.02702702702702703|\n",
      "| 39433|   28|                 0.0|\n",
      "| 34713|  103|                 0.0|\n",
      "| 20467|   88|0.011363636363636364|\n",
      "| 15162|   81|                 0.0|\n",
      "| 18759|   95|                 0.0|\n",
      "| 45769|  185|                 0.0|\n",
      "| 38651|   33|                 0.0|\n",
      "|110871|  106|0.009433962264150943|\n",
      "| 37864|  102|                 0.0|\n",
      "+------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView('clickstream') # регистрируем DF как таблицу\n",
    "ctr_df = spark.sql(\"select ad_id, \\\n",
    "                               count(CASE WHEN event = 'view' THEN 1 END) as views, \\\n",
    "                               count(CASE WHEN event = 'click' THEN 1 END) / count(CASE WHEN event = 'view' THEN 1 END) as ctr \\\n",
    "                        from clickstream \\\n",
    "                        group by ad_id \\\n",
    "                        having views != 0\")\n",
    "ctr_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "| ad_id|                 CTR|\n",
      "+------+--------------------+\n",
      "| 47217|0.045454545454545456|\n",
      "| 40515| 0.02857142857142857|\n",
      "| 33412|                 0.0|\n",
      "| 33602|             0.01875|\n",
      "| 20596|  0.0062402496099844|\n",
      "|119169|0.007861635220125786|\n",
      "|116158|                 0.0|\n",
      "| 46938| 0.02127659574468085|\n",
      "|114166|                 0.0|\n",
      "| 43921|                 0.0|\n",
      "| 98184| 0.02702702702702703|\n",
      "| 39433|                 0.0|\n",
      "| 34713|                 0.0|\n",
      "| 20467|0.011363636363636364|\n",
      "| 15162|                 0.0|\n",
      "| 18759|                 0.0|\n",
      "| 45769|                 0.0|\n",
      "| 38651|                 0.0|\n",
      "|110871|0.009433962264150943|\n",
      "| 37864|                 0.0|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_cond_lambda = lambda cond: F.sum(F.when(cond, 1).otherwise(0))\n",
    "    \n",
    "# Вариант без SQL кода:\n",
    "ctr_df = df.groupBy('ad_id') \\\n",
    "               .agg(count_cond_lambda(F.col('event') == 'view').alias('views'), \\\n",
    "                    count_cond_lambda(F.col('event') == 'click').alias('clicks')) \\\n",
    "               .select('ad_id', F.expr(\"clicks / views\").alias('CTR')) # селектим только CTR, чтобы в итоговой выборке не дропать clicks и views\n",
    "ctr_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------------+---------+------+------+-------+--------------------+----------+\n",
      "| ad_id|target_audience_count|has_video|is_cpm|is_cpc|ad_cost|                 CTR|days_count|\n",
      "+------+---------------------+---------+------+------+-------+--------------------+----------+\n",
      "| 45061|              1955269|        0|     1|     0|  200.6|0.007547169811320755|         2|\n",
      "|121288|               232011|        0|     1|     0|  187.4|                 0.0|         2|\n",
      "|102737|                 4410|        0|     0|     1|   60.7|                 0.0|         2|\n",
      "|107564|                62711|        0|     1|     0|  217.3|0.011627906976744186|         2|\n",
      "|  4922|              1183501|        0|     0|     1|   60.1|0.013651877133105802|         2|\n",
      "| 10325|                20779|        0|     1|     0|  211.7|                 0.0|         2|\n",
      "| 41458|                 6864|        0|     1|     0|  205.8|0.024752475247524754|         2|\n",
      "| 45831|               132960|        1|     1|     0|  193.8|                 0.0|         4|\n",
      "|101985|              1452003|        0|     1|     0|  213.0|0.007874015748031496|         2|\n",
      "| 16589|                  109|        0|     1|     0|  212.7|0.007357859531772575|         2|\n",
      "| 44582|               115877|        0|     1|     0|  195.8| 0.00766016713091922|         3|\n",
      "| 26269|               112674|        1|     1|     0|  213.9|0.005242463958060288|         2|\n",
      "| 45259|                48173|        0|     1|     0|  200.4|0.002898550724637681|         2|\n",
      "|108707|               108133|        0|     0|     1|   51.7|0.005747126436781609|         2|\n",
      "|120299|              1637837|        0|     1|     0|  200.0|0.002049180327868...|         2|\n",
      "| 37798|               324442|        0|     0|     1|   41.4|                 0.0|         2|\n",
      "| 38376|               123516|        1|     1|     0|  214.9|0.013036393264530146|         3|\n",
      "|112994|                32756|        0|     1|     0|  214.0|                 0.0|         2|\n",
      "|120299|              1637837|        0|     1|     0|  200.0|0.002049180327868...|         2|\n",
      "| 44582|               115877|        0|     1|     0|  195.8| 0.00766016713091922|         3|\n",
      "+------+---------------------+---------+------+------+-------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# подсчет ctr\n",
    "def get_ctr_df(df):\n",
    "    count_cond_lambda = lambda cond: F.sum(F.when(cond, 1).otherwise(0))\n",
    "    \n",
    "    # Вариант без SQL кода:\n",
    "    ctr_df = df.groupBy('ad_id') \\\n",
    "               .agg(count_cond_lambda(F.col('event') == 'view').alias('views'), \\\n",
    "                    count_cond_lambda(F.col('event') == 'click').alias('clicks'), \\\n",
    "                   F.countDistinct(F.when(F.col('event') == 'view', col('date'))).alias('days_count'))\\\n",
    "               .select('ad_id', F.expr(\"clicks / views\").alias('CTR'), 'days_count') # селектим только CTR, чтобы в итоговой выборке не дропать clicks и views\n",
    "    ctr_df.cache()\n",
    "    return ctr_df\n",
    "\n",
    "\n",
    "# выбираем нужные поля из старого df и вычисляем необходимые\n",
    "ndf = df.select(['ad_id', \n",
    "                     'target_audience_count',  \n",
    "                     'has_video', \n",
    "                     (col('ad_cost_type') == 'CPM').cast('integer').alias('is_cpm'), \n",
    "                     (col('ad_cost_type') == 'CPC').cast('integer').alias('is_cpc'), \n",
    "                     'ad_cost']) \\\n",
    "            .join(get_ctr_df(df), 'ad_id', 'left')\n",
    "    # делим df на тренирующую и тестовую выборки\n",
    "ndf.show(20)\n",
    "ndf.count()                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Многие преобразования можно было бы выполнить в рамках одной группировки с применением нескольких агрегирующих функций. Попробуйте уменьшить число join операции, применяя множественную агрегацию. Пример: from pyspark.sql.functions import min, max, col df.groupBy('taxi_id') \\ .agg(min(col('trip_start_timestamp')), max(col('trip_start_timestamp'))) \\ .show() Это поможет сразу за одну агрегацию наити все колонки. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------------+-----+------+----------+\n",
      "| ad_id|target_audience_count|views|clicks|days_count|\n",
      "+------+---------------------+-----+------+----------+\n",
      "| 47217|                 7121|   22|     1|         2|\n",
      "| 40515|                11533|  140|     4|         2|\n",
      "| 33602|              3277386|  480|     9|         2|\n",
      "| 33412|                 7195|   35|     0|         2|\n",
      "| 20596|              1106999|  641|     4|         2|\n",
      "| 46938|                23187|   47|     1|         2|\n",
      "|119169|                35019|  636|     5|         2|\n",
      "| 43921|                 7807|   22|     0|         1|\n",
      "|116158|             46707392| 5589|     0|         2|\n",
      "|114166|                 7350|   26|     0|         2|\n",
      "| 20467|              3388754|   88|     1|         2|\n",
      "| 98184|                 1231|   37|     1|         2|\n",
      "| 39433|                 6759|   28|     0|         2|\n",
      "| 15162|             32214433|   81|     0|         2|\n",
      "| 34713|               139368|  103|     0|         2|\n",
      "| 45769|               130509|  185|     0|         2|\n",
      "| 47013|               101583|  270|     4|         2|\n",
      "| 32622|               136254|   42|     2|         2|\n",
      "|110871|                20147|  106|     1|         2|\n",
      "| 38651|                92362|   33|     0|         2|\n",
      "+------+---------------------+-----+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "965"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# выбираем нужные поля из старого df и вычисляем необходимые\n",
    "ndf = df.groupBy('ad_id') \\\n",
    "        .agg(F.max('target_audience_count').alias('target_audience_count'), \\\n",
    "            count_cond_lambda(F.col('event') == 'view').alias('views'), \\\n",
    "             count_cond_lambda(F.col('event') == 'click').alias('clicks'), \\\n",
    "             F.countDistinct(F.when(F.col('event') == 'view', col('date'))).alias('days_count'))       \n",
    "\n",
    "    \n",
    "    # делим df на тренирующую и тестовую выборки\n",
    "ndf.show(20)\n",
    "ndf.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------------+---------+------+------+-------+----------+--------------------+\n",
      "| ad_id|target_audience_count|has_video|is_cpm|is_cpc|ad_cost|days_count|                 CTR|\n",
      "+------+---------------------+---------+------+------+-------+----------+--------------------+\n",
      "| 32798|                 1377|        0|     1|     0|  199.2|         2|0.043478260869565216|\n",
      "|120382|                  640|        0|     1|     0|  204.9|         2|                 0.0|\n",
      "| 43506|                38220|        0|     0|     1|   52.2|         2|                 0.0|\n",
      "| 37809|               772494|        0|     1|     0|  192.0|         2|0.013836477987421384|\n",
      "| 17920|                11710|        0|     1|     0|  204.2|         2|0.014084507042253521|\n",
      "| 13856|               217626|        0|     0|     1|   48.2|         2|0.012539184952978056|\n",
      "|108836|               253481|        0|     1|     0|  202.4|         2|                 0.0|\n",
      "| 45999|              1153387|        0|     1|     0|  203.8|         2|                 0.0|\n",
      "|113273|               163454|        0|     1|     0|  204.4|         2|                 0.0|\n",
      "| 38300|                43192|        0|     1|     0|  197.3|         2|0.011363636363636364|\n",
      "|107729|             39538534|        0|     1|     0|  190.9|         2|6.338165507378275E-4|\n",
      "| 45981|                20500|        0|     1|     0|  192.5|         2|0.023255813953488372|\n",
      "| 27845|                51515|        0|     1|     0|  210.1|         2| 0.01276595744680851|\n",
      "| 37135|               135893|        0|     1|     0|  199.5|         2|0.009925558312655087|\n",
      "| 32276|                28709|        0|     1|     0|  205.6|         2|0.009153318077803204|\n",
      "| 13320|               504181|        0|     0|     1|   54.4|         2|0.008264462809917356|\n",
      "| 39539|                48429|        0|     1|     0|  191.8|         2|0.025906735751295335|\n",
      "| 17461|                 2317|        0|     1|     0|  202.5|         2|                 0.0|\n",
      "| 99233|               163924|        0|     1|     0|  189.6|         2|                 0.0|\n",
      "|120098|                19005|        0|     1|     0|  202.5|         2|                 0.0|\n",
      "+------+---------------------+---------+------+------+-------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "965"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nndf = df.select(['ad_id', \n",
    "                  'target_audience_count',  \n",
    "                  'has_video', \n",
    "                  'event', \n",
    "                  'date',\n",
    "                  (col('ad_cost_type') == 'CPM').cast('integer').alias('is_cpm'), \n",
    "                  (col('ad_cost_type') == 'CPC').cast('integer').alias('is_cpc'), \n",
    "                  'ad_cost']) \\\n",
    "        .groupBy('ad_id', 'target_audience_count', 'has_video', 'is_cpm', 'is_cpc', 'ad_cost') \\\n",
    "        .agg(count_cond_lambda(F.col('event') == 'view').alias('views'), \\\n",
    "             count_cond_lambda(F.col('event') == 'click').alias('clicks'), \\\n",
    "             F.countDistinct(F.when(F.col('event') == 'view', col('date'))).alias('day_count')) \\\n",
    "         .select(['*', F.expr(\"clicks / views\").alias('CTR')]) \\\n",
    "         .drop('views', 'clicks')\n",
    "nndf.show()\n",
    "nndf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ctr_df(df):\n",
    "    count_cond_lambda = lambda cond: F.sum(F.when(cond, 1).otherwise(0))\n",
    "    \n",
    "    # Вариант без SQL кода:\n",
    "    ctr_df = df.groupBy('ad_id') \\\n",
    "               .agg(count_cond_lambda(F.col('event') == 'view').alias('views'), \\\n",
    "                    count_cond_lambda(F.col('event') == 'click').alias('clicks'), \\\n",
    "                    F.countDistinct(F.when(F.col('event') == 'view', col('date'))).alias('day_count')) \\\n",
    "               .select('ad_id', 'day_count', F.expr(\"clicks / views\").alias('CTR')) # селектим только CTR, чтобы в итоговой выборке не дропать clicks и views\n",
    "    return ctr_df\n",
    "    \n",
    "ndf = df.select(['ad_id', \n",
    "                     'target_audience_count',  \n",
    "                     'has_video', \n",
    "                     (col('ad_cost_type') == 'CPM').cast('integer').alias('is_cpm'), \n",
    "                     (col('ad_cost_type') == 'CPC').cast('integer').alias('is_cpc'), \n",
    "                     'ad_cost']) \\\n",
    "        .join(get_ctr_df(df), 'ad_id', 'left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "cannot resolve '`event`' given input columns: [ad_cost, ad_id, clicks, day_count, has_video, is_cpc, is_cpm, target_audience_count, views];;\n'Project [ad_id#4, target_audience_count#10, has_video#9, 'event, 'date, is_cpm#3501, is_cpc#3502, ad_cost#8, day_count#3523L, (cast(clicks#3522L as double) / cast(views#3520L as double)) AS CTR#3534]\n+- Aggregate [ad_id#4, target_audience_count#10, has_video#9, is_cpm#3501, is_cpc#3502, ad_cost#8], [ad_id#4, target_audience_count#10, has_video#9, is_cpm#3501, is_cpc#3502, ad_cost#8, sum(cast(CASE WHEN (event#2 = view) THEN 1 ELSE 0 END as bigint)) AS views#3520L, sum(cast(CASE WHEN (event#2 = click) THEN 1 ELSE 0 END as bigint)) AS clicks#3522L, count(distinct CASE WHEN (event#2 = view) THEN date#0 END) AS day_count#3523L]\n   +- Project [ad_id#4, target_audience_count#10, has_video#9, event#2, date#0, cast((ad_cost_type#7 = CPM) as int) AS is_cpm#3501, cast((ad_cost_type#7 = CPC) as int) AS is_cpc#3502, ad_cost#8]\n      +- Relation[date#0,time#1,event#2,platform#3,ad_id#4,client_union_id#5,compaign_union_id#6,ad_cost_type#7,ad_cost#8,has_video#9,target_audience_count#10] parquet\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-138-4a85e45f6b06>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m                      \u001b[1;34m'ad_cost'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                      \u001b[1;34m'day_count'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                      F.expr(\"clicks / views\").alias('CTR')]) \\\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[1;31m#.drop('views', 'clicks') # перечислять нужные поля в select'e показалось визуально некрасивым)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark-3.0.1-bin-hadoop2.7\\python\\pyspark\\sql\\dataframe.py\u001b[0m in \u001b[0;36mselect\u001b[1;34m(self, *cols)\u001b[0m\n\u001b[0;32m   1419\u001b[0m         \u001b[1;33m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mu'Alice'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mu'Bob'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m         \"\"\"\n\u001b[1;32m-> 1421\u001b[1;33m         \u001b[0mjdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jcols\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1422\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1305\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1307\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark-3.0.1-bin-hadoop2.7\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    132\u001b[0m                 \u001b[1;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m                 \u001b[1;31m# JVM exception message.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m                 \u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark-3.0.1-bin-hadoop2.7\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(e)\u001b[0m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: cannot resolve '`event`' given input columns: [ad_cost, ad_id, clicks, day_count, has_video, is_cpc, is_cpm, target_audience_count, views];;\n'Project [ad_id#4, target_audience_count#10, has_video#9, 'event, 'date, is_cpm#3501, is_cpc#3502, ad_cost#8, day_count#3523L, (cast(clicks#3522L as double) / cast(views#3520L as double)) AS CTR#3534]\n+- Aggregate [ad_id#4, target_audience_count#10, has_video#9, is_cpm#3501, is_cpc#3502, ad_cost#8], [ad_id#4, target_audience_count#10, has_video#9, is_cpm#3501, is_cpc#3502, ad_cost#8, sum(cast(CASE WHEN (event#2 = view) THEN 1 ELSE 0 END as bigint)) AS views#3520L, sum(cast(CASE WHEN (event#2 = click) THEN 1 ELSE 0 END as bigint)) AS clicks#3522L, count(distinct CASE WHEN (event#2 = view) THEN date#0 END) AS day_count#3523L]\n   +- Project [ad_id#4, target_audience_count#10, has_video#9, event#2, date#0, cast((ad_cost_type#7 = CPM) as int) AS is_cpm#3501, cast((ad_cost_type#7 = CPC) as int) AS is_cpc#3502, ad_cost#8]\n      +- Relation[date#0,time#1,event#2,platform#3,ad_id#4,client_union_id#5,compaign_union_id#6,ad_cost_type#7,ad_cost#8,has_video#9,target_audience_count#10] parquet\n"
     ]
    }
   ],
   "source": [
    "count_cond_lambda = lambda cond: F.sum(F.when(cond, 1).otherwise(0))\n",
    "    \n",
    "ndf = df.select(['ad_id', \n",
    "                     'target_audience_count',  \n",
    "                     'has_video', \n",
    "                     'event', \n",
    "                     'date',\n",
    "                     (col('ad_cost_type') == 'CPM').cast('integer').alias('is_cpm'), \n",
    "                     (col('ad_cost_type') == 'CPC').cast('integer').alias('is_cpc'), \n",
    "                     'ad_cost']) \\\n",
    "            .groupBy('ad_id', 'target_audience_count', 'has_video', 'is_cpm', 'is_cpc', 'ad_cost') \\\n",
    "            .agg(count_cond_lambda(F.col('event') == 'view').alias('views'), \\\n",
    "                 count_cond_lambda(F.col('event') == 'click').alias('clicks'), \\\n",
    "                 F.countDistinct(F.when(F.col('event') == 'view', col('date'))).alias('day_count')) \\\n",
    "            .select([ \n",
    "                     'ad_id', \n",
    "                     'target_audience_count',  \n",
    "                     'has_video', \n",
    "                     'is_cpm',\n",
    "                     'is_cpc',\n",
    "                     'ad_cost',\n",
    "                     'day_count',\n",
    "                     F.expr(\"clicks / views\").alias('CTR')]) \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
