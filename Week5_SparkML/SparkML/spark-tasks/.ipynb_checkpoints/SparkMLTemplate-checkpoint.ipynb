{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import mean,col,split, col, regexp_extract, when, lit\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import QuantileDiscretizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "#set seed\n",
    "random.seed(1234)\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"PySparkML\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://Al-PC:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkML</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7c0dd08>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## №1 Линейная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите данные для применения линейной регрессии <a href=\"https://github.com/AlexKbit/stepik-ds-course/raw/master/Week5/SparkML/spark-tasks/linear_regression.parquet\">linear_regression.parquet</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_df = spark.read.parquet('linear_regression.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+\n",
      "|              label|            features|\n",
      "+-------------------+--------------------+\n",
      "| -9.490009878824548|(10,[0,1,2,3,4,5,...|\n",
      "| 0.2577820163584905|(10,[0,1,2,3,4,5,...|\n",
      "| -4.438869807456516|(10,[0,1,2,3,4,5,...|\n",
      "|-19.782762789614537|(10,[0,1,2,3,4,5,...|\n",
      "| -7.966593841555266|(10,[0,1,2,3,4,5,...|\n",
      "+-------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создайте учителя линейной регресии со следующими параметрами:\n",
    "maxIter=20\n",
    "regParam=0.5\n",
    "elasticNetParam=0.75<br>\n",
    "<a href=\"https://spark.apache.org/docs/latest/ml-classification-regression.html#linear-regression\">LinearRegression</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = #Ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполните обучения на загруженных данных и сохраните результат в переменную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrModel = #Ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдите следующие параметры полученной модели rootMeanSquaredError (RMSE), r2 и округлити их до 3его знака."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## №2 Кластеризация (K-Means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите данные для применения из <a href=\"https://github.com/AlexKbit/stepik-ds-course/raw/master/Week5/SparkML/spark-tasks/wine.parquet\">wine.parquet</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df = #Ваш код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примените <a href=\"https://spark.apache.org/docs/latest/ml-features.html#vectorassembler\">VectorAssembler</a> для создания вектора фич (задействуйте все свойства, кроме Customer_Segment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = #Ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cоздайте учителя KMeans со следующими параметрами K=3 Seed=1<br>\n",
    "Обучите модель и примените ее к тому же вектору.\n",
    "Документация по <a href=\"https://spark.apache.org/docs/latest/ml-clustering.html#k-means\">KMeans</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдите силуэт с евклидовым расстоянием в квадрате для данных по вину(округлите до четвертого знака).\n",
    "<br><a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.evaluation.ClusteringEvaluator\">ClusteringEvaluator</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## №3 DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузити датасет из файла <a href=\"https://github.com/AlexKbit/stepik-ds-course/raw/master/Week5/SparkML/spark-tasks/iris.parquet\">iris.parquet</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = #Ваш код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Составьте из наших признаков вектор применив <a href=\"https://spark.apache.org/docs/latest/ml-features.html#vectorassembler\">VectorAssembler</a> как колонку features.\n",
    "<br> Задействуйте все признаки, кроме species, так как он является целевым."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используйте <a href=\"https://spark.apache.org/docs/latest/ml-features.html#stringindexer\">StringIndexer</a> и сделайте новый признак с именем type из целевого признака species который является категориальным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ваш код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируем выборки на обучение и тест."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_data, test_data) = iris_df.randomSplit([0.8, 0.2],seed = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создайте и обучите <a href=\"https://spark.apache.org/docs/latest/ml-classification-regression.html#decision-tree-classifier\">DecisionTreeClassifier</a> на датасете для обучения.\n",
    "Полученную модель используйте над тестовым датасетом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "#Ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используйте <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.evaluation.MulticlassClassificationEvaluator\">MulticlassClassificationEvaluator</a> (помните что целевая фича это - type) для оценки качества модели по метрике accuracy.<br>Какая точность полученной модели?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## №4 Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создайте и обучите <a href=\"https://spark.apache.org/docs/latest/ml-classification-regression.html#random-forest-classifier\">RandomForestClassifier</a> из 10 деревьев на датасете для обучения.\n",
    "Полученную модель примените к тестовому датасету.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "#Ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используйте <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.evaluation.MulticlassClassificationEvaluator\">MulticlassClassificationEvaluator</a> (помните что целевая фича это - type) для оценки качества модели по метрике accuracy.<br>Какая точность полученной модели?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## №5 Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Займемся оптимизацией гиперпараметров для модели.\n",
    "Примените <a href='https://spark.apache.org/docs/latest/ml-tuning.html#train-validation-split'>TrainValidationSplit</a> для оптимизации гиперпараметров используя подготовленный вами выше датасет <a href=\"https://github.com/AlexKbit/stepik-ds-course/raw/master/Week5/SparkML/spark-tasks/iris.parquet\">iris.parquet</a> на модели <a href=\"https://spark.apache.org/docs/latest/ml-classification-regression.html#random-forest-classifier\">RandomForestClassifier</a> совместно с <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.evaluation.MulticlassClassificationEvaluator\">MulticlassClassificationEvaluator</a>.\n",
    "<br>Ваша цель определить оптимальные значения параметров из следующих диапазонов:\n",
    "<br>impurity = [\"entropy\", \"gini\"]\n",
    "<br>maxDepth = [2, 3, 4, 5]\n",
    "<br>numTrees = [3, 6, 9, 12, 15, 18, 21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = #Ваш код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Num Trees: {}'.format(model.bestModel._java_obj.getNumTrees()))\n",
    "print('Max Depth: {}'.format(model.bestModel._java_obj.getMaxDepth()))\n",
    "print('Impurity: {}'.format(model.bestModel._java_obj.getImpurity()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
